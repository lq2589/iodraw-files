<mxGraphModel dx="1414" dy="745" grid="0" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="827" pageHeight="1169" math="0" shadow="0"><root><mxCell id="wQsLFmqBHB1WWPcFXXlB-0"/><mxCell id="wQsLFmqBHB1WWPcFXXlB-1" parent="wQsLFmqBHB1WWPcFXXlB-0"/><mxCell id="OlG0hAXD_eKM0gIazNCE-11" style="edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;" edge="1" parent="wQsLFmqBHB1WWPcFXXlB-1" source="OlG0hAXD_eKM0gIazNCE-6" target="OlG0hAXD_eKM0gIazNCE-7"><mxGeometry relative="1" as="geometry"/></mxCell><mxCell id="OlG0hAXD_eKM0gIazNCE-6" value="初始化PPO算法的策略网络和价值网络" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="wQsLFmqBHB1WWPcFXXlB-1"><mxGeometry x="231" y="409" width="248" height="45" as="geometry"/></mxCell><mxCell id="OlG0hAXD_eKM0gIazNCE-7" value="策略网络和价值网络的目标函数构建" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="wQsLFmqBHB1WWPcFXXlB-1"><mxGeometry x="231" y="483" width="248" height="45" as="geometry"/></mxCell><mxCell id="OlG0hAXD_eKM0gIazNCE-8" value="环境交互，训练数据获取" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="wQsLFmqBHB1WWPcFXXlB-1"><mxGeometry x="231" y="556" width="248" height="45" as="geometry"/></mxCell><mxCell id="OlG0hAXD_eKM0gIazNCE-9" value="网络梯度计算和参数更新" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="wQsLFmqBHB1WWPcFXXlB-1"><mxGeometry x="231" y="632" width="248" height="45" as="geometry"/></mxCell><mxCell id="OlG0hAXD_eKM0gIazNCE-10" value="策略优化和迭代" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="wQsLFmqBHB1WWPcFXXlB-1"><mxGeometry x="231" y="701" width="248" height="45" as="geometry"/></mxCell></root></mxGraphModel>